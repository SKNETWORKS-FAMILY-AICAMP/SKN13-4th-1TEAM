# csv_loader.py
"""
ë³¸ íŒŒì¼ì€ datasetì— ìˆëŠ” csvíŒŒì¼ì„ ëª¨ë‘ ì½ê³ ,
chroma_dbë¥¼ êµ¬ì¶•í•˜ëŠ” íŒŒì¼ì…ë‹ˆë‹¤.
chroma_dbë¥¼ êµ¬ì¶•í–ˆìœ¼ë©´ ì´ íŒŒì¼ì„ ì‹¤í–‰ì‹œí‚¤ì§€ ë§ˆì‹œì˜¤.
ì¤‘ê°„ì— ì„¤ì¹˜ì— ì‹¤íŒ¨í–ˆì„ ê²½ìš°, 
chroma_db í´ë”ë¥¼ ì‚­ì œ í›„, ë‹¤ì‹œ ì´ íŒŒì¼ì„ ì‹¤í–‰ì‹œí‚¤ì‹œì˜¤.
"""


import os
import glob
from dotenv import load_dotenv
from langchain_openai import OpenAIEmbeddings
from langchain_community.document_loaders import CSVLoader
from langchain_chroma import Chroma

load_dotenv()

def build_chroma_vector_store(data_dir: str = "dataset",
                              persist_dir: str = "chroma_db",
                              chunk_size: int = 100):

    pattern = os.path.join(data_dir, "*.csv")
    csv_file_paths = glob.glob(pattern)

    all_csv_docs = []
    for path in csv_file_paths:
        loader = CSVLoader(
            file_path=path,
            csv_args={'delimiter': ","},
            encoding='utf-8',
            content_columns=["ì§ˆë¬¸","ë³¸ë¬¸"]
        )
        docs = loader.load()
        all_csv_docs.extend(docs)

    embedding_model = OpenAIEmbeddings(model="text-embedding-3-large")

    # Chroma ìƒì„± or ë¶ˆëŸ¬ì˜¤ê¸°
    vector_store = Chroma(
        embedding_function=embedding_model,
        collection_name="QnA",
        persist_directory=persist_dir
        )

    # ë¬¸ì„œ ì‚½ì…
    for i in range(0, len(all_csv_docs), chunk_size):
        chunk = all_csv_docs[i:i+chunk_size]
        vector_store.add_documents(chunk)
        print(f"ğŸ”¹{i+1}~{min(i+chunk_size, len(all_csv_docs))} ë¬¸ì„œ Chromaì— ì €ì¥ ì™„ë£Œ")    # 14637

    # ë””ìŠ¤í¬ì— ì €ì¥
    print(f"âœ… ì €ì¥ ì™„ë£Œ â†’ {persist_dir}")

build_chroma_vector_store()