import os
import time
import requests
import fitz  # PyMuPDF
import pandas as pd
from io import BytesIO
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# β–¶ μ„¤μ •
# CHROMEDRIVER_PATH = r"C:\Aicamp\chromedriver-win64\chromedriver-win64\chromedriver.exe"
BASE_URL = "https://opengov.seoul.go.kr"
SAVE_PATH = "press_crawled.csv"

# β–¶ μ…€λ λ‹μ›€ λ“λΌμ΄λ²„ μ„¤μ •
options = Options()
options.add_argument("--start-maximized")
options.add_argument("--disable-blink-features=AutomationControlled")
options.add_argument("user-agent=Mozilla/5.0")
# options.add_argument("--headless")  # ν•„μ” μ‹ μ‚¬μ©

# driver = webdriver.Chrome(service=Service(CHROMEDRIVER_PATH), options=options)
driver = webdriver.Chrome(options=options)
wait = WebDriverWait(driver, 10)

data = []
article_id = 1

# ν¬λ΅¤λ§ν•  νμ΄μ§€ λ²”μ„ μ •ν•κΈ°
num_start = 1
num_end = 3
for i in range(num_start, num_end + 1):
    page_url = f"{BASE_URL}/press/list?page={i}"
    print(f"β… λ¦¬μ¤νΈ μ ‘μ† μ„±κ³µ: {i}νμ΄μ§€")
    driver.get(page_url)
    time.sleep(1)

    try:
        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "table tbody tr td.data-title.aLeft > a")))
        elements = driver.find_elements(By.CSS_SELECTOR, "table tbody tr td.data-title.aLeft > a")
        detail_links = [el.get_attribute("href") for el in elements]
        print(f"π“ μƒμ„Ένμ΄μ§€ λ§ν¬ μ: {len(detail_links)}κ°")

        for link in detail_links:
            try:
                driver.get(link)
                time.sleep(1.5)
                soup = BeautifulSoup(driver.page_source, "html.parser")

                # μ λ© μμ§‘
                title_tag = soup.select_one("#content > div > div.view-content.view-content-article > h3")
                if not title_tag:
                    print("β μ λ© μ—†μ, μ¤ν‚µ")
                    continue
                title = title_tag.get_text(strip=True)

                # PDF λ§ν¬ μμ§‘
                pdf_tag = soup.select_one("#content > div > div.view-content.view-content-article a[href$='.pdf']")
                if pdf_tag:
                    href = pdf_tag.get("href")
                    if isinstance(href, str):
                        pdf_url = BASE_URL + href
                        print(f"π” μƒμ„Ένμ΄μ§€: {link}")
                        print(f"π‘‰ μ λ©: {title}")
                        print(f"π‘‰ PDF λ§ν¬: {pdf_url}")
                    else:
                        print(f"β PDF href μ¤λ¥: {title} / {link}")
                        continue
                else:
                    pdf_tag = soup.select_one("#content > div > div.view-content.view-content-article > div:nth-child(8) > ul > li:nth-child(1) > span > a:nth-child(2) > i")
                    if pdf_tag:
                        href = pdf_tag.get("href")
                        if isinstance(href, str):
                            pdf_url = BASE_URL + href
                            print(f"π” μƒμ„Ένμ΄μ§€: {link}")
                            print(f"π‘‰ μ λ©: {title}")
                            print(f"π‘‰ PDF λ§ν¬: {pdf_url}")
                        else:
                            print(f"β PDF href μ¤λ¥: {title} / {link}")
                            continue
                    else:
                        print(f"β PDF μ—†μ: {title} / {link}")
                        continue

                # PDF μ”μ²­ λ° νμ‹±
                res = requests.get(pdf_url)
                doc = fitz.open(stream=BytesIO(res.content), filetype="pdf")
                text = "\n".join([page.get_text() for page in doc])

                data.append({
                    "id": article_id,
                    "μ§λ¬Έ": title,
                    "λ³Έλ¬Έ": text.strip()
                })
                article_id += 1

            except Exception as e:
                print(f"β μƒμ„Ένμ΄μ§€ μ²λ¦¬ μ¤λ¥: {e}")
                continue

    except Exception as e:
        print(f"β μ „μ²΄ ν¬λ΅¤λ§ μ¤λ¥ (page {i}): {e}")
        continue

driver.quit()

# β–¶ CSV μ €μ¥
df = pd.DataFrame(data)
df.to_csv(SAVE_PATH, index=False, encoding="utf-8-sig")
print(f"\nβ… ν¬λ΅¤λ§ μ™„λ£: μ΄ {len(df)}κ±΄ μμ§‘ β†’ {SAVE_PATH}")
